---
title: "Lecture 4 - Model Selection"
subtitle: "<br> Econometrics 1"
author: "Vincent Bagilet"
date: "2024-10-08"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: libs
    css: mediocre-themer.css
    nature:
      countIncrementalSlides: no
      highlightLines: yes
      highlightStyle: github
      ratio: '16:9'
      titleSlideClass: [right, middle, inverse]
---


```{r setup_fe, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/FE/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 300,
               fig.align = "center",
               dev.args = list(bg="transparent"))  
```  

```{r themer, include=FALSE}
library(tidyverse)
library(knitr)
library(xaringan)
library(mediocrethemes)
library(here)
library(broom)

# set knit directory to "Document directory"

set.seed(12)

xaringan_mediocre(pal = "portal")
```

class: right, middle, inverse

# Quizz

---

class: right, middle, inverse

# End of last week's slides

---
# What's Next?

- We now know:

  - How to estimate a model with OLS
  
  - The necessary conditions for the estimator to have nice properties
  
  - How to consider various functional forms in our model
  
--

- How do we choose **which variables to include** in our model?

- What happens if we omit some variables? 

- What if we have irrelevant variables in our econometrics model?

---

class: right, middle, inverse

# Omitted Variables

---
class: titled, middle

```{r DAG, echo=FALSE, fig.asp=0.5, out.width='70%', warning=FALSE, fig.align="center", fig.dpi=200}
library(ggdag)

dagify(Wage ~ Educ + Gender,
       Educ ~ Gender,
       exposure = c("Educ" ,"Wage"),
       latent = "Gender",
       coords = list(x = c(Wage = 2, Educ = 1, Gender = 1.5),
                     y = c(Wage = 1, Educ = 1, Gender = 0))
  ) |> 
  ggdag_status(text_size = 3) +
  theme_dag_blank(base_family = "Lato", legend.position = "none") +
  scale_mediocre_d(pal = "portal", background = FALSE) + 
  annotate(#parameters
    "text", 
    x = 1.5, 
    y = 1.1, 
    label = "beta",
    parse = TRUE,
    color = "black",
    size = 5
  ) 
```

---
# Simulation

- Gender affects education and wage

- Actual DGP: $Wage_i = \alpha + \beta Educ_i + \delta Gender_i + e_i$

- Omitting Gender: $Wage_i = \alpha + \beta Educ_i + e_i$

- True effect: $\beta = 2000$

--

```{r sim_data, echo=FALSE, fig.asp=0.8, fig.align='center', message=FALSE,  warning=FALSE, out.width='70%', fig.dpi=300}

baseline_param <- tibble(
  N = 1000,
  mu_educ = 3, 
  sigma_educ = 1,
  sigma_u = 8000,
  alpha = 15000,
  beta = 2000,
  gamma = -1,
  delta = -2000
)

n_iter <- 100

#function to generate data
generate_data <- function(N,
                          mu_educ,
                          sigma_educ,
                          sigma_u, 
                          alpha,
                          beta,
                          gamma,
                          delta) {
  
  data <- tibble(id = 1:N) %>%
    mutate(
      female = rbernoulli(N),
      educ = rnorm(N, mu_educ, sigma_educ) + gamma*female,
      u = rnorm(N, 0, sigma_u),
      wage = alpha + beta*educ + delta*female + u
    ) 
}

run_estim <- function(data) {
  reg_short <- data |> 
    lm(formula = wage ~ educ) |> 
    summary() |> 
    broom::tidy(conf.int = TRUE, conf.level = 0.95) |> 
    filter(term == "educ") |> 
    select(-term) |> 
    mutate(model = "Omitted Variable", .before = 1)
  
   reg_long <- data |> 
    lm(formula = wage ~ educ + female) |> 
    summary() |> 
    broom::tidy(conf.int = TRUE, conf.level = 0.95) |> 
    filter(term == "educ") |> 
    select(-term) |> 
    mutate(model = "Actual DGP", .before = 1)
   
  bind_rows(reg_short, reg_long)
}

compute_sim <- function(...) {
  generate_data(...) %>% 
    run_estim() %>% 
    cbind(as_tibble(list(...))) |> #add parameters used for generation
    as_tibble()
}

one_sim <- baseline_param |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

one_sim |> 
  select(1:5) |> 
  kable()
```

---

```{r plot_sim, echo=FALSE, fig.asp=0.8, fig.align='center', message=FALSE,  warning=FALSE, out.width='70%', fig.dpi=300}

sim_res <- baseline_param |> 
  uncount(n_iter) |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

sim_res |> 
  ggplot(aes(x = estimate, color = model, fill = model)) + 
  geom_density() + 
  labs(
    title = "Distribution of Estimates",
    x = "Estimate",
    y = "Density",
    color = NULL, 
    fill = NULL
  )
```

---
# On a Real Dataset

### Long regression

```{r ovb_wooldrige_long, echo=FALSE}
library(wooldridge)

lm(data = wage1, wage ~ educ + female) |> 
  tidy() |> 
  kable()
```

### Short regression

```{r ovb_wooldrige_short, echo=FALSE}
lm(data = wage1, wage ~ educ) |> 
  tidy() |> 
  kable()
```

---
# Dealing with Variable Selection

- **Why** would we omit variables?

--

  - Economic theory not perfectly defined $\Rightarrow$ we do not know what to include or not
  
  - Inobserved variables
  
- **How** can we choose?

--

  1. Estimate multiple models with different functional forms
  
  2. Compare model performance
  
---
class: titled, middle

# Under-specification

- When relevant inputs are omitted (there impact on the)

- Can create Omitted Variable Bias (OVB)

---


```{r plot_sim_0, echo=FALSE, fig.asp=0.8, fig.align='center', message=FALSE,  warning=FALSE, out.width='70%', fig.dpi=300}

param_no_effect_educ <- baseline_param |> 
  mutate(gamma = 0)

sim_res_no_effect_educ <- param_no_effect_educ |> 
  uncount(n_iter) |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

sim_res_no_effect_educ |> 
  ggplot(aes(x = estimate, color = model, fill = model)) + 
  geom_density() + 
  labs(
    title = "Distribution of Estimates",
    subtitle = "If No Effect of Gender on Education",
    x = "Estimate",
    y = "Density",
    color = NULL, 
    fill = NULL
  )
```

---
class: titled, middle

# Regression Table Comparison

### Effect of Gender on Education (initial regression)

```{r one_sim_again, echo=FALSE}
one_sim |> 
  select(1:5) |> 
  kable()
```

### No effect of Gender on Education

```{r one_sim_no_effect_educ, echo=FALSE}
one_sim_no_effect_educ <- param_no_effect_educ |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

one_sim_no_effect_educ |> 
  select(1:5) |> 
  kable()
```


---

```{r plot_sim_02, echo=FALSE, fig.asp=0.8, fig.align='center', message=FALSE,  warning=FALSE, out.width='70%', fig.dpi=300}
param_no_effect_wage <- baseline_param |> 
  mutate(delta = 0)

sim_res_no_effect_wage <- param_no_effect_wage |> 
  uncount(n_iter) |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

sim_res_no_effect_wage |> 
  ggplot(aes(x = estimate, color = model, fill = model)) + 
  geom_density() + 
  labs(
    title = "Distribution of Estimates",
    subtitle = "If No Effect of Gender on Wage",
    x = "Estimate",
    y = "Density",
    color = NULL, 
    fill = NULL
  )
```

---
class: titled, middle

# Regression Table Comparison

### Effect of Gender on Wage (initial regression)

```{r one_sim_3, echo=FALSE}
one_sim |> 
  select(1:5) |> 
  kable()
```

### No effect of Gender on Education

```{r one_sim_no_effect_wage, echo=FALSE}
one_sim_no_effect_wage <- param_no_effect_wage |> 
  purrr::pmap(compute_sim) |> 
  bind_rows()

one_sim_no_effect_wage |> 
  select(1:5) |> 
  kable()
```

---
class: right, middle

# Maths on the board

---
class: titled, middle

# Summary for Under-specification

- Problematic to ignore variables that are correlated with both $x$ and $y$

- Ok if only correlated with $x$ or $y$

- But, controling for variables correlated with $y$ $\searrow$ variance of errors 

  $\Rightarrow$ $\searrow$ variance of estimator

- OVB unobserved $\Rightarrow$ cannot really asses its sign or magnitude

---
class: right, middle, inverse

# Over-Specification

---
class: titled, middle

# Over-Specification

- Over-Specification = including irrelevant variables

- Will not create bias

- But will affect the **variance** of our estimator

- Creates a **bias-variance trade-off**

$$\mathbb{V}[\hat{\beta}] = \dfrac{\sigma_u^2}{n \sigma_x^2}$$

---
class: titled, middle

# When to Adjust or Not?

- Including a variable to our model if not interested in its paramater is called **controling** or **adjusting**

- If including the variable $\searrow$ variance of errors, include it ...

- **But** only if does not decreases too much the variance of our explanatory variable of interest

- If correlated with $x$, will $\nearrow$ variance of errors

- In practice, often prefer to include too many variables than too little:

  - Variance decreases with sample size but bias does not

---
class: right, middle, inverse

# Model Selection

---
class: titled, middle

# General Idea

- Evaluate the capacity to fit the relationship between the explained and explanatory variables

- Should **explain a large share of the variability** of the explained variable

- For instance explain why some mode individuals earn more than others

- Variance of $y$ can be decomposed into that of the estimated response and error

$$Var[y | X] = Var[\hat{y} | X ] + Var[\hat{e} | X]$$

---
class: titled, middle

# $R^2$

- Proportion of the variance in $y$ that is explained by the model

- Measures how well the model explains the variability in $y$

- Varies between 0 and 1

- Increases with the number of covariates $\Rightarrow$ use the adjusted- $R^2$

---
class: right, middle

# Maths on the board


---
class: titled, middle

# Sum(s) of Squares

We define the following quantities:

- **TSS**: the Total Sum of Squares, $\quad TSS = \sum_{i=1}^{n}(y_i - \bar{y})^2$

- **ESS**: the Explained Sum of Squares, $\quad ESS = \sum_{i=1}^{n}(\hat{y_i} - \bar{y})^2$

- **RSS**: the Residual Sum of Squares, $\quad RSS = \sum_{i=1}^{n}(\hat{y_i} - y_i)^2$

We can show that:

$$TSS = ESS + RSS$$

---
class: titled, middle

# $R^2$ and formulas

- Proportion of the variance in $y$ that is explained by the model so:

$$R^2 = \dfrac{ESS}{TSS} = 1 - \dfrac{RSS}{TSS}$$
- It is also the square fo the correlation coefficient between $y$ and $\hat{y}$ (hence its name)

---
class: titled, middle

# Information Criteria

- To select between different models, we can also use different information criteria 

  - **AIC**: Akaike Information Criterion

  - **BIC**: Bayesian Information Criterion

- *Approach*:
  
  1. Compute the information criterion for each specification
  
  1. Select the model that minimizes the information criterion
  
- However, it says nothing about the quality of the model

---
class: right, middle, inverse

# Thanks!

 





